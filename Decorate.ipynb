{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T10:43:26.244601Z",
     "start_time": "2019-01-07T10:43:26.231071Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import ensemble\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score, precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T10:43:27.616261Z",
     "start_time": "2019-01-07T10:43:27.368261Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decorate(object):\n",
    "\n",
    "    def __init__(self, tree_parameters, C_max_size=100, R_size=0.5, Itr_max=300, generator='basic'):\n",
    "        \"\"\"\n",
    "        Initializing the Decorate that will be in use to build the ensemble classifier\n",
    "        :param tree_parameters: The parameters of the base learning algorithm ('Decision Tree Classifier')\n",
    "        :param C_max_size: Maximum desired ensemble size\n",
    "        :param R_size: Factor that determines number of artificial examples to generate\n",
    "        :param Itr_max: Maximum number of iterations to build an ensemble\n",
    "        :param generator: 'basic' VS 'GAN'\n",
    "        \"\"\"\n",
    "        self.tree_parameters = tree_parameters\n",
    "        self.C_max_size = C_max_size\n",
    "        self.R_size = R_size\n",
    "        self.Itr_max = Itr_max\n",
    "        self.C_all = []\n",
    "        self.classes = None\n",
    "        self.generator = generator\n",
    "\n",
    "    def fit(self, X_train, Y_train):\n",
    "        \"\"\"\n",
    "        Runs the DECORATE algorithm from the article (\"Creating Diversity In Ensembles Using Artificial Data\" p.8)\n",
    "        :param X_train: The training input samples\n",
    "        :param Y_train: The target values\n",
    "        \"\"\"\n",
    "        C_i = DecisionTreeClassifier(**self.tree_parameters)\n",
    "        self.C_all.append(C_i.fit(X_train, Y_train))\n",
    "        C_size, I_number = 1, 1\n",
    "        self.classes = pd.unique(Y_train)\n",
    "        ensemble_error = self._compute_error(X_train, Y_train)\n",
    "        while C_size < self.C_max_size and I_number < self.Itr_max:\n",
    "            if self.generator == 'basic':\n",
    "                training_artificial_examples = self._generate_artificial_examples_basic(X_train)\n",
    "            else:\n",
    "                print(\"training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\")\n",
    "                training_artificial_examples = self._generate_artificial_examples_basic(X_train)\n",
    "            artificial_labels_examples = self._generate_artificial_labels(training_artificial_examples)\n",
    "            training_data = pd.concat([X_train, training_artificial_examples], axis=0)\n",
    "            training_labels = np.concatenate((Y_train, artificial_labels_examples), axis=0)\n",
    "            C_candidate = DecisionTreeClassifier(**self.tree_parameters)\n",
    "            self.C_all.append(C_candidate.fit(training_data, training_labels))\n",
    "            training_error = self._compute_error(X_train, Y_train)\n",
    "            if training_error <= ensemble_error:\n",
    "                ensemble_error = training_error\n",
    "                C_size += 1\n",
    "            else:\n",
    "                self.C_all.pop()\n",
    "            I_number = I_number + 1\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Predict class probabilities of the input samples X\n",
    "        :param X: Input samples\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        probas = np.zeros((X.shape[0], len(self.classes)))\n",
    "        for tree in self.C_all:\n",
    "            probas += tree.predict_proba(X)\n",
    "        return probas / len(self.C_all)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict class value for X\n",
    "        :param X: Input samples\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        probas_list = self.predict_proba(X)\n",
    "        results = np.argmax(probas_list, axis=1)\n",
    "        return results\n",
    "\n",
    "    def _compute_error(self, X, Y):\n",
    "        \"\"\"\n",
    "        Compute ensemble error\n",
    "        :param X: Input samples\n",
    "        :param Y: Ground truth (correct) labels\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        pred = np.argmax(self.predict_proba(X), axis=1)\n",
    "        ensemble_error = round(1 - accuracy_score(Y, pred), 5)\n",
    "        return ensemble_error\n",
    "\n",
    "    def _generate_artificial_examples_basic(self, X):\n",
    "        \"\"\"\n",
    "        Generate artificial training data by randomly picking data points from an approximation of the training-data \n",
    "        distribution.\n",
    "        :param X: Input samples\n",
    "        \"\"\"\n",
    "        number_of_samples = int(X.shape[0] * self.R_size)\n",
    "        artificial_examples = np.zeros((number_of_samples, X.shape[1]))\n",
    "        for col_index, column_name in enumerate(X.columns):\n",
    "            column = X[column_name]\n",
    "            if len(pd.unique(column)) == 2 and (pd.unique(column)[0] == 0 or pd.unique(column)[0] == 1) and (\n",
    "                    pd.unique(column)[1] == 0 or pd.unique(column)[1] == 1):\n",
    "                proba_1 = column.tolist().count(1) / len(column)\n",
    "                artificial_examples[:, col_index] = np.random.choice([0, 1], size=number_of_samples,\n",
    "                                                                     p=[1 - proba_1, proba_1])\n",
    "            else:\n",
    "                artificial_examples[:, col_index] = np.random.normal(np.mean(column), np.std(column),\n",
    "                                                                     size=number_of_samples)\n",
    "        return pd.DataFrame(artificial_examples, columns=X.columns)\n",
    "\n",
    "    def _generate_artificial_labels(self, training_artificial_examples):\n",
    "        \"\"\"\n",
    "        first, giving to each training artificial example the class membership probabilities predicted by the ensemble.\n",
    "        then, replace zero probabilities with 0.001 and normalize it. next, labels are selected, such that the \n",
    "        probability of selection is inversely proportional to the current ensembleâ€™s predictions.\n",
    "        :param training_artificial_examples: Generated artificial training data\n",
    "        \"\"\"\n",
    "        labels = np.zeros(training_artificial_examples.shape[0])\n",
    "        probabilities = self.predict_proba(training_artificial_examples)\n",
    "        normalized_probabilities = self._normalize_probas(probabilities)\n",
    "\n",
    "        for prob in range(len(normalized_probabilities)):\n",
    "            normalized_probabilities[prob] = 1 / normalized_probabilities[prob]\n",
    "            normalized_probabilities[prob] = normalized_probabilities[prob] / np.sum(normalized_probabilities[prob])\n",
    "            labels[prob] = np.random.choice(self.classes, p=normalized_probabilities[prob])\n",
    "        return labels\n",
    "\n",
    "    def _normalize_probas(self, probabilities):\n",
    "        \"\"\"\n",
    "        Replace zero probabilities with 0.001 and normalize the probabilities to make it a distribution.\n",
    "        :param probabilities: Probabilities predicted by the ensemble\n",
    "        \"\"\"\n",
    "        for probas in range(len(probabilities)):\n",
    "            probabilities[probas] = [0.001 if p == 0.0 else p for p in probabilities[probas]] / np.sum(\n",
    "                probabilities[probas])\n",
    "        return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T10:43:29.235233Z",
     "start_time": "2019-01-07T10:43:29.143735Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_i_fold(Y_test, pred, fit_time,prediction_time, total_scores_func, dataset, generator_name):\n",
    "    \"\"\"\n",
    "    Calculating the different scores of each cross validation run and save it to a scores dictionary. \n",
    "    :param Y_test: Ground truth (correct) labels\n",
    "    :param pred: Predicted labels, as returned by a classifier.\n",
    "    :param fit_time: Amount of tme that the fit function took\n",
    "    :param prediction_time: Amount of tme that the pred function took\n",
    "    :param total_scores_func: saves all CV results\n",
    "    :param dataset: data set name\n",
    "    :param generator_name: 'basic' VS 'GAN'\n",
    "    :return: total_scores_func (dictionary)\n",
    "    \"\"\"\n",
    "    configuration = 'c1'\n",
    "    accuracy = round(accuracy_score(Y_test, pred), 3)\n",
    "    precision = round(precision_score(Y_test, pred, average='macro'), 3)\n",
    "    recall = round(recall_score(Y_test, pred, average='macro'), 3)\n",
    "    f1 = round(f1_score(Y_test, pred, average='macro'), 3)\n",
    "    total_scores_func[dataset][generator_name][configuration]['fit_time'].append(round(float(fit_time), 2)) \n",
    "    total_scores_func[dataset][generator_name][configuration]['prediction_time'].append(round(float(prediction_time), 2)) \n",
    "    total_scores_func[dataset][generator_name][configuration]['accuracy'].append(accuracy)\n",
    "    total_scores_func[dataset][generator_name][configuration]['precision'].append(precision)\n",
    "    total_scores_func[dataset][generator_name][configuration]['recall'].append(recall)\n",
    "    total_scores_func[dataset][generator_name][configuration]['f1'].append(f1)\n",
    "    return total_scores_func\n",
    "\n",
    "def write_data_set_results_to_csv(dataset,total_scores,generators):\n",
    "    \"\"\"\n",
    "    Writes the CV results to a csv file.\n",
    "    :param dataset: data set name\n",
    "    :param total_scores: saves all CV results\n",
    "    :param generators: 'basic' VS 'GAN'\n",
    "    \"\"\"\n",
    "    configuration='c1'\n",
    "    for generator_name in generators:\n",
    "        log_list_test = [dataset,generator_name,\n",
    "                         np.mean(total_scores[dataset][generator_name][configuration]['fit_time']),\n",
    "                         np.mean(total_scores[dataset][generator_name][configuration]['prediction_time']),\n",
    "                         np.mean(total_scores[dataset][generator_name][configuration]['accuracy']),\n",
    "                         np.mean(total_scores[dataset][generator_name][configuration]['precision']),\n",
    "                         np.mean(total_scores[dataset][generator_name][configuration]['recall']),\n",
    "                         np.mean(total_scores[dataset][generator_name][configuration]['f1']) ]\n",
    "        writer = csv.writer(open(\"results.csv\", \"a\"), lineterminator='\\n', dialect='excel')\n",
    "        writer.writerow(log_list_test)\n",
    "\n",
    "def write_headline():\n",
    "    \"\"\"\n",
    "    Writes the file header.\n",
    "    \"\"\"\n",
    "    log_list_header = ['dataset', 'generator',  'fit_time','prediction_time', 'accuracy', 'precision', 'recall', 'f1']\n",
    "    writer = csv.writer(open(\"results.csv\", \"a\"), lineterminator='\\n', dialect='excel')\n",
    "    writer.writerow(log_list_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Utiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T10:43:30.595962Z",
     "start_time": "2019-01-07T10:43:30.583459Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_sets = { 'biodeg': 'datasets/biodeg.csv',\n",
    "               'glass':'datasets/glass.csv', 'image segmentation':'datasets/image segmentation.csv',\n",
    "               'Indian Liver Patient Dataset (ILPD)':'datasets/Indian Liver Patient Dataset (ILPD).csv', 'isolet':'datasets/isolet.csv',\n",
    "               'magic04':'datasets/magic04.csv','movement_libras':'datasets/movement_libras.csv','wilt':'datasets/wilt.csv',\n",
    "               'Wine_classification':'datasets/Wine_classification.csv'}\n",
    "\n",
    "generators = ['basic','GAN']\n",
    "\n",
    "configuration='c1'\n",
    "\n",
    "tree_parameters={'max_depth': 5, 'min_samples_leaf': 10 , 'class_weight': 'balanced'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T10:43:40.619498Z",
     "start_time": "2019-01-07T10:43:32.853001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name: biodeg\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n",
      "training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-203-e2a4b1343866>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mclf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDecorate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree_parameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC_max_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mItr_max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgenerator_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-200-3e3f0ac01e56>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_train, Y_train)\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"training_artificial_examples = self._generate_artificial_examples_GAN(X_train)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mtraining_artificial_examples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generate_artificial_examples_basic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0martificial_labels_examples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generate_artificial_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_artificial_examples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[0mtraining_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_artificial_examples\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mtraining_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0martificial_labels_examples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-200-3e3f0ac01e56>\u001b[0m in \u001b[0;36m_generate_artificial_labels\u001b[1;34m(self, training_artificial_examples)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \"\"\"\n\u001b[0;32m    109\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_artificial_examples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[0mprobabilities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_artificial_examples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m         \u001b[0mnormalized_probabilities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_normalize_probas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-200-3e3f0ac01e56>\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mprobas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC_all\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[0mprobas\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mprobas\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    830\u001b[0m         \"\"\"\n\u001b[0;32m    831\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tree_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 832\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    833\u001b[0m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    375\u001b[0m         \u001b[1;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[0;32m    379\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    525\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m     \"\"\"\n\u001b[1;32m--> 501\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "write_headline()\n",
    "total_scores={}\n",
    "for dataset in data_sets:\n",
    "    # Reading and processing the data\n",
    "    ds = pd.read_csv(data_sets[dataset])\n",
    "    print(\"Dataset name: {}\".format(dataset))\n",
    "    ds = ds.dropna()\n",
    "    le = LabelEncoder()\n",
    "    Y = ds.pop('class')\n",
    "    X = pd.get_dummies(ds)\n",
    "    Y =le.fit_transform(Y)\n",
    "    Y=pd.DataFrame(data=Y, columns=['class'])\n",
    "    X, Y = shuffle(X, Y, random_state=10)    \n",
    "    kf = KFold(n_splits=10)\n",
    "    kf.get_n_splits(X)\n",
    "    total_scores.setdefault(dataset, {})\n",
    "    \n",
    "    for generator_name in generators:\n",
    "        Scores = {\n",
    "        'c1': {'fit_time': [],'prediction_time': [], 'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "        }\n",
    "        total_scores[dataset].setdefault(generator_name, Scores)\n",
    "        \n",
    "    # Run the CV\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        for generator_name in generators:           \n",
    "            X_train=X.iloc[train_index]\n",
    "            X_test=X.iloc[test_index]\n",
    "            Y_train=Y.iloc[train_index]\n",
    "            Y_test=Y.iloc[test_index] \n",
    "            clf=Decorate(tree_parameters, C_max_size=100, R_size=0.4, Itr_max=100,generator=generator_name)\n",
    "            start_time = time.time()\n",
    "            clf.fit(X_train,Y_train['class'].values.tolist())\n",
    "            fit_time = (time.time() - start_time)\n",
    "            start_time = time.time()\n",
    "            pred = clf.predict(X_test)\n",
    "            prediction_time = (time.time() - start_time)\n",
    "            seconds = (time.time() - start_time)\n",
    "            total_scores = evaluate_i_fold(Y_test, pred, fit_time,prediction_time, total_scores, dataset, generator_name)\n",
    "    write_data_set_results_to_csv(dataset, total_scores, generators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T10:43:40.631001Z",
     "start_time": "2019-01-07T10:43:38.262Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1.0,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16.0,
    "lenType": 16.0,
    "lenVar": 40.0
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
